<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>reveal.js</title>

	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/black.css">

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="plugin/highlight/monokai.css">
	<style>
		.reveal h1,
		.reveal h2,
		.reveal h3,
		.reveal h4,
		.reveal h5 {
			text-transform: none;
		}
	</style>
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section>
				<img class="r-stretch" src="media/ClearEye_logo_redim.png" alt="logo">
				<h1>ClearEye Technologies</h1>

			</section>
			
			<section>
				<p>Because no robotics company <br /> should operate without vision-based AI</p> 
			</section>

			<section>
				<img src="media/2021_Musk_quote.png">

				<p>We don't pretend like Elon Musk that cameras are enough to operate, but they are definitely a vital element of the perception stack of an up-to-date AGV</p>
			</section>			
			
			<section>
				<p>Relying on vision is a must-have for :
					<ul>
						<li>safety</li>
						<li>efficiency</li>
					</ul>
				</p> 
			</section>
			
			<section>
				<p class="fragment fade-in-then-out">We offer a <em>cost-efficient</em> solution to ...</p>
					<ul>
						<li class="fragment">detect efficiently human presence</li>
						<li class="fragment">monitor your assets in real-time <br />to build a true <em class="fragment highlight-blue">digital twin</em></li>
					</ul>
			
			</section>

			<section>
				<h2>Embedded safety</h2>
			</section>

			<section>
				<p>Why ?<br> Adapting the robot behaviour when a human <br> (or an unexpected event) is detected</p>
				<br>
				<p>How ?<br> Leveraging real-time computer vision, <br> bringing semantic information</p>
			</section>

			<section>
				<section>
					<video data-autoplay src="media/mask_rcnn_R_50_FPN_3x.mp4"></video>
				</section>
				<section>
					The previous result was obtained with a model from the R-CNN family (Region Based Convolutional Neural Networks), which is state-of-the-art for object detection.
					<br><br>
					We also tested SAM (Segment Anything Model), released by Meta AI in April 2023, which is a promptable segmentation system :
				</section>
				<section>
					<img src="media/SAM.png">
				</section>
			</section>

			<section>
				<h2>Why is our solution <br />cost-efficient ?</h2>
			</section>

			<section>
				<section><p>Because we can detect skeletons with low-res cameras</p>
					<small>(here with another model called YOLOX, introduced in 2021)</small>
					<video data-autoplay src="media/hackathon_yolox_skeleton.mp4"></video>
				</section>
				<section>
					<p>Even when the persons are far from the robot</p>
					<video data-autoplay src="media/hackathon_even_far.mp4"></video>
				</section>

				<section>
					<p>And in harsh conditions</p>
					<video data-autoplay src="media/hackathon-even harsh environment.mp4"></video>
				</section>
				
				<section>
					<p>We can handle fisheye lenses the same way</p>
					<img src="media/rcnn_fisheye.png">
				</section>

			</section>

			<section>
				<p><h2>Build a true digital twin</h2></p>
			</section>

			<section>
				<p>Collecting vehicle information, including orientation</p>
				<img src="media/vehicle_information.png">
			</section>

			<section>
				<p>Monitoring infrastructure dynamically<br>(avoiding de-synchronisations ...)</p>
				<video data-autoplay src="media/parking_zone_monitoring.mp4"></video>

			</section>


			<section>
				<p>Builiding THE ultimate digital twin of a compound !</p>
				<video data-autoplay src="media/Screencast_Aurelien.mp4"></video>
			</section>

			<section>
				<h2>Next steps</h2>
			</section>
			<section>
				<section>
					Improving robot alignment using vehicle segmentation
					<img src="media/vehicle_segmentation.png">
				</section>

				<section>
					And also :
					<ul>
						<li>Improve localisation performance with Visual SLAM</li>
					</ul>
				</section>
			</section>



			<section>
				<section>
					<p>
						<h2>
							Why you should invest in ClearEye Technologies 
						</h2>
						<ul>
							<li>
								Because we address the growing need for enhanced safety and efficiency in robotized environments
							</li>
							<li>
								Because the autonomous mobile robot market is forecast to experience significant growth in the coming years
							</li>
						</ul>
					</p>
				</section>
				<section>
					<ul>
						<li>
							Because ClearEye technology is well-positioned to capitalize on this growth. The company's camera-based perception system can be integrated into a wide range of autonomous robots, expanding its market reach and potential customer base.
						</li>
					</ul>
				</section>
			</section>

			<section>
				<h2>Conclusion</h2>
			</section>

			<section>
				<p>ClearEye Technologies' unique focus on pedestrian detection and traffic zone surveillance sets it apart from competitors, enhancing its market value</p>
			</section>			

			<section>
				<p>Don't trust competitors' solutions !</p>
				<img src="media/cell_phone_detection.png">
			</section>

			<section>
				<p>Special thanks to Raphael, Jordy, Yanis and Mahmoud for the acquisitions at LYS !</p>
				<img class="r-stretch"src="media/ST0007.jpg">
			</section>

		</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/markdown/markdown.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,

			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes]
		});
	</script>
</body>

</html>